# VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects



This repository provides source code for our paper:

[VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects](https://hyperplane-lab.github.io/vat-mart/)

[Ruihai Wu](https://warshallrho.github.io)\*, [Yan Zhao](https://sxy7147.github.io)\*, [Kaichun Mo](https://www.cs.stanford.edu/~kaichun)\*, [Zizheng Guo](https://guozz.cn/), [Yian Wang](https://galaxy-qazzz.github.io/), [Tianhao Wu](https://tianhaowuhz.github.io/), [Qingnan Fan](https://fqnchina.github.io/), [Xuelin Chen](https://xuelin-chen.github.io/), [Leonidas J. Guibas](https://geometry.stanford.edu/member/guibas/), [Hao Dong](http://cfcs.pku.edu.cn/baoquan/) (\* indicates joint first authors)

ICLR, 2022

Currently we have released the code for perception networks, and we are working on purifying and releasing other code in recent days (06/30/2022).

Project Page: https://hyperplane-lab.github.io/vat-mart/



## Citations

Please cite our work if you find it useful:

    @inproceedings{
    wu2022vatmart,
    title={{VAT}-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D {ART}iculated Objects},
    author={Ruihai Wu and Yan Zhao and Kaichun Mo and Zizheng Guo and Yian Wang and Tianhao Wu and Qingnan Fan and Xuelin Chen and Leonidas Guibas and Hao Dong},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=iEx3PiooLy}
    }

